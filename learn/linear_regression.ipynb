{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import  numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Regressor(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        # here must specify shape instead of tensor !\n",
    "        # [dim_in, dim_out]\n",
    "        self.w = self.add_variable('w', [13, 1])\n",
    "        # [dim_out]\n",
    "        self.b = self.add_variable('b', [1])\n",
    "\n",
    "        print(self.w.shape, self.b.shape)\n",
    "        print(type(self.w), tf.is_tensor(self.w), self.w.name)\n",
    "        print(type(self.b), tf.is_tensor(self.b), self.b.name)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.matmul(x, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 2s 27us/step\n",
      "(404, 13) (404,) (102, 13) (102,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_val, y_val) = keras.datasets.boston_housing.load_data()\n",
    "x_train, x_val = x_train.astype(np.float32), x_val.astype(np.float32)\n",
    "# (404, 13) (404,) (102, 13) (102,)\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
    "dataset_val = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 1) (1,)\n",
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True w:0\n",
      "<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'> True b:0\n",
      "epoch=000\ttrain_loss=39695.023438\tval_loss=36500.550781\n",
      "epoch=010\ttrain_loss=42.267826\tval_loss=124.677483\n",
      "epoch=020\ttrain_loss=38.738976\tval_loss=120.318687\n",
      "epoch=030\ttrain_loss=35.925831\tval_loss=114.442184\n",
      "epoch=040\ttrain_loss=32.724255\tval_loss=107.796265\n",
      "epoch=050\ttrain_loss=29.603855\tval_loss=101.227325\n",
      "epoch=060\ttrain_loss=26.820536\tval_loss=95.070663\n",
      "epoch=070\ttrain_loss=24.471895\tval_loss=89.491501\n",
      "epoch=080\ttrain_loss=22.579117\tval_loss=84.549286\n",
      "epoch=090\ttrain_loss=21.120289\tval_loss=80.235916\n",
      "epoch=100\ttrain_loss=20.048559\tval_loss=76.501846\n",
      "epoch=110\ttrain_loss=19.305262\tval_loss=73.276276\n",
      "epoch=120\ttrain_loss=18.829227\tval_loss=70.481697\n",
      "epoch=130\ttrain_loss=18.562893\tval_loss=68.043526\n",
      "epoch=140\ttrain_loss=18.455795\tval_loss=65.895645\n",
      "epoch=150\ttrain_loss=18.465954\tval_loss=63.982647\n",
      "epoch=160\ttrain_loss=18.559933\tval_loss=62.260128\n",
      "epoch=170\ttrain_loss=18.711973\tval_loss=60.693569\n",
      "epoch=180\ttrain_loss=18.902721\tval_loss=59.256660\n",
      "epoch=190\ttrain_loss=19.117865\tval_loss=57.929478\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "\n",
    "\n",
    "model = Regressor()\n",
    "criteon = keras.losses.MeanSquaredError()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
    "\n",
    "for epoch in range(200):\n",
    "    for step, (x, y) in enumerate(dataset_train):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # [b, 1]\n",
    "            y_hat = model(x)\n",
    "            # [b]\n",
    "            y_hat = tf.squeeze(y_hat, axis=1)\n",
    "            # [b] vs [b]\n",
    "            train_loss = criteon(y, y_hat)\n",
    "\n",
    "        grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        for x, y in dataset_val:\n",
    "            # [b, 1]\n",
    "            y_hat = model(x)\n",
    "            # [b]\n",
    "            y_hat = tf.squeeze(y_hat, axis=1)\n",
    "            # [b] vs [b]\n",
    "            val_loss = criteon(y, y_hat)\n",
    "            print(\"epoch={:0>3d}\\ttrain_loss={:.6f}\\tval_loss={:.6f}\".format(epoch,train_loss,val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
