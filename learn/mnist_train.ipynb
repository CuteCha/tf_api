{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "print(tf.__version__)\n",
    "# from    tensorflow.keras import datasets, layers, optimizers, Sequential, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(data, label),_ = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "0\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(data.min())\n",
    "print(data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = tf.convert_to_tensor(data, dtype=tf.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.batch(32).repeat(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  2570      \n",
      "=================================================================\n",
      "Total params: 335,114\n",
      "Trainable params: 335,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.Dense(256, activation='relu'),\n",
    "                          keras.layers.Dense(256, activation='relu'),\n",
    "                          keras.layers.Dense(256, activation='relu'),\n",
    "                          keras.layers.Dense(10)])\n",
    "model.build(input_shape=(None, 28*28))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01)\n",
    "acc = keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=000000\tloss=0.085429\tacc=0.9786\n",
      "step=000200\tloss=0.071440\tacc=0.9786\n",
      "step=000400\tloss=0.078449\tacc=0.9759\n",
      "step=000600\tloss=0.068370\tacc=0.9752\n",
      "step=000800\tloss=0.068183\tacc=0.9766\n",
      "step=001000\tloss=0.105982\tacc=0.9731\n",
      "step=001200\tloss=0.077731\tacc=0.9777\n",
      "step=001400\tloss=0.066634\tacc=0.9762\n",
      "step=001600\tloss=0.061008\tacc=0.9711\n",
      "step=001800\tloss=0.082098\tacc=0.9775\n",
      "step=002000\tloss=0.077317\tacc=0.9812\n",
      "step=002200\tloss=0.023894\tacc=0.9780\n",
      "step=002400\tloss=0.069606\tacc=0.9756\n",
      "step=002600\tloss=0.081268\tacc=0.9761\n",
      "step=002800\tloss=0.044286\tacc=0.9769\n",
      "step=003000\tloss=0.056662\tacc=0.9784\n",
      "step=003200\tloss=0.091101\tacc=0.9764\n",
      "step=003400\tloss=0.053910\tacc=0.9750\n",
      "step=003600\tloss=0.037452\tacc=0.9745\n",
      "step=003800\tloss=0.089894\tacc=0.9809\n",
      "step=004000\tloss=0.068468\tacc=0.9819\n",
      "step=004200\tloss=0.069973\tacc=0.9767\n",
      "step=004400\tloss=0.067486\tacc=0.9777\n",
      "step=004600\tloss=0.112071\tacc=0.9778\n",
      "step=004800\tloss=0.065653\tacc=0.9780\n",
      "step=005000\tloss=0.055686\tacc=0.9786\n",
      "step=005200\tloss=0.135092\tacc=0.9761\n",
      "step=005400\tloss=0.124555\tacc=0.9773\n",
      "step=005600\tloss=0.024839\tacc=0.9822\n",
      "step=005800\tloss=0.055473\tacc=0.9800\n",
      "step=006000\tloss=0.072307\tacc=0.9803\n",
      "step=006200\tloss=0.085509\tacc=0.9778\n",
      "step=006400\tloss=0.042760\tacc=0.9797\n",
      "step=006600\tloss=0.036984\tacc=0.9792\n",
      "step=006800\tloss=0.027748\tacc=0.9780\n",
      "step=007000\tloss=0.031462\tacc=0.9795\n",
      "step=007200\tloss=0.207278\tacc=0.9745\n",
      "step=007400\tloss=0.075311\tacc=0.9794\n",
      "step=007600\tloss=0.077708\tacc=0.9828\n",
      "step=007800\tloss=0.039556\tacc=0.9803\n",
      "step=008000\tloss=0.073606\tacc=0.9806\n",
      "step=008200\tloss=0.033889\tacc=0.9802\n",
      "step=008400\tloss=0.028972\tacc=0.9808\n",
      "step=008600\tloss=0.063147\tacc=0.9794\n",
      "step=008800\tloss=0.076533\tacc=0.9795\n",
      "step=009000\tloss=0.079062\tacc=0.9778\n",
      "step=009200\tloss=0.025253\tacc=0.9772\n",
      "step=009400\tloss=0.031859\tacc=0.9845\n",
      "step=009600\tloss=0.076881\tacc=0.9820\n",
      "step=009800\tloss=0.019345\tacc=0.9814\n",
      "step=010000\tloss=0.092869\tacc=0.9812\n",
      "step=010200\tloss=0.056112\tacc=0.9822\n",
      "step=010400\tloss=0.088301\tacc=0.9781\n",
      "step=010600\tloss=0.032643\tacc=0.9825\n",
      "step=010800\tloss=0.116252\tacc=0.9795\n",
      "step=011000\tloss=0.042642\tacc=0.9781\n",
      "step=011200\tloss=0.051148\tacc=0.9820\n",
      "step=011400\tloss=0.040545\tacc=0.9830\n",
      "step=011600\tloss=0.092051\tacc=0.9828\n",
      "step=011800\tloss=0.049945\tacc=0.9809\n",
      "step=012000\tloss=0.035128\tacc=0.9819\n",
      "step=012200\tloss=0.030888\tacc=0.9820\n",
      "step=012400\tloss=0.067603\tacc=0.9820\n",
      "step=012600\tloss=0.078309\tacc=0.9803\n",
      "step=012800\tloss=0.059794\tacc=0.9791\n",
      "step=013000\tloss=0.060485\tacc=0.9803\n",
      "step=013200\tloss=0.095784\tacc=0.9844\n",
      "step=013400\tloss=0.046033\tacc=0.9836\n",
      "step=013600\tloss=0.044890\tacc=0.9827\n",
      "step=013800\tloss=0.077019\tacc=0.9814\n",
      "step=014000\tloss=0.026695\tacc=0.9833\n",
      "step=014200\tloss=0.141982\tacc=0.9827\n",
      "step=014400\tloss=0.048459\tacc=0.9827\n",
      "step=014600\tloss=0.118613\tacc=0.9798\n",
      "step=014800\tloss=0.041435\tacc=0.9795\n",
      "step=015000\tloss=0.059203\tacc=0.9862\n",
      "step=015200\tloss=0.057322\tacc=0.9828\n",
      "step=015400\tloss=0.062259\tacc=0.9841\n",
      "step=015600\tloss=0.046937\tacc=0.9830\n",
      "step=015800\tloss=0.047168\tacc=0.9836\n",
      "step=016000\tloss=0.066139\tacc=0.9809\n",
      "step=016200\tloss=0.059742\tacc=0.9834\n",
      "step=016400\tloss=0.045682\tacc=0.9828\n",
      "step=016600\tloss=0.044074\tacc=0.9789\n",
      "step=016800\tloss=0.062960\tacc=0.9828\n",
      "step=017000\tloss=0.053993\tacc=0.9858\n",
      "step=017200\tloss=0.016193\tacc=0.9847\n",
      "step=017400\tloss=0.048155\tacc=0.9842\n",
      "step=017600\tloss=0.062772\tacc=0.9833\n",
      "step=017800\tloss=0.032552\tacc=0.9837\n",
      "step=018000\tloss=0.034355\tacc=0.9845\n",
      "step=018200\tloss=0.072266\tacc=0.9830\n",
      "step=018400\tloss=0.040807\tacc=0.9814\n",
      "step=018600\tloss=0.024139\tacc=0.9817\n"
     ]
    }
   ],
   "source": [
    "for step, (x,y) in enumerate(dataset):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # [b, 28, 28] => [b, 784]\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        # [b, 784] => [b, 10]\n",
    "        y_hat = model(x)\n",
    "        # [b] => [b, 10]\n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        # [b, 10]\n",
    "        loss = tf.square(y_hat - y_onehot)\n",
    "        # [b]\n",
    "        loss = tf.reduce_sum(loss) / 32\n",
    "\n",
    "    acc.update_state(tf.argmax(y_hat, axis=1), y)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    if step % 200==0:\n",
    "        print(\"step={:0>6d}\\tloss={:.6f}\\tacc={:.4f}\".format(step,loss,acc.result().numpy()))\n",
    "        acc.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
